{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Ollama with VDS Tunnel in Google Colab\n",
    "\n",
    "## Настройка\n",
    "\n",
    "1. В Colab добавьте секреты (значок ключа слева):\n",
    "   - vds_host: IP вашего VDS\n",
    "   - ssh_key: приватный SSH-ключ в base64 (конвертируйте командой `base64 -w0 tunnel_key`)\n",
    "\n",
    "2. На VDS должны быть настроены:\n",
    "   - Публичный ключ в `~/.ssh/authorized_keys`\n",
    "   - Открытый порт 11434\n",
    "   - Параметр `GatewayPorts yes` в `/etc/ssh/sshd_config`\n",
    "\n",
    "3. Используйте GPU runtime (Runtime -> Change runtime type -> GPU)\n",
    "\n",
    "## 1. Установка пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama\n",
    "!curl https://ollama.ai/install.sh | sh\n",
    "\n",
    "# Install CUDA and SSH\n",
    "!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n",
    "!sudo apt-get update && sudo apt-get install -y cuda-drivers openssh-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Настройка окружения и импорт зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "import base64\n",
    "\n",
    "# Проверка наличия всех необходимых секретов\n",
    "required_secrets = ['vds_host', 'ssh_key']\n",
    "missing_secrets = [secret for secret in required_secrets if not userdata.get(secret)]\n",
    "if missing_secrets:\n",
    "    raise ValueError(f\"Missing required secrets: {', '.join(missing_secrets)}\\n\"\n",
    "                    \"Add them in Colab: Left sidebar -> Key icon -> Add new secret\\n\"\n",
    "                    \"Required secrets:\\n\"\n",
    "                    \"- vds_host: IP адрес VDS\\n\"\n",
    "                    \"- ssh_key: SSH приватный ключ в base64\")\n",
    "\n",
    "# Создаем директорию .ssh и сохраняем ключ\n",
    "ssh_dir = os.path.expanduser('~/.ssh')\n",
    "os.makedirs(ssh_dir, mode=0o700, exist_ok=True)\n",
    "\n",
    "# Декодируем и сохраняем SSH ключ\n",
    "key_data = base64.b64decode(userdata.get('ssh_key')).decode()\n",
    "key_path = os.path.join(ssh_dir, 'tunnel_key')\n",
    "with open(key_path, 'w') as f:\n",
    "    f.write(key_data)\n",
    "os.chmod(key_path, 0o600)\n",
    "\n",
    "# Конфигурация\n",
    "VDS_HOST = userdata.get('vds_host')\n",
    "VDS_USER = 'tunnel'  # Фиксированный пользователь из скрипта установки\n",
    "LOCAL_PORT = 11434\n",
    "\n",
    "# Set LD_LIBRARY_PATH for NVIDIA\n",
    "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание Modelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем Modelfile\n",
    "modelfile_content = \"\"\"\n",
    "FROM qwen:14b\n",
    "PARAMETER num_ctx 128000\n",
    "\"\"\"\n",
    "\n",
    "with open('Modelfile', 'w') as f:\n",
    "    f.write(modelfile_content)\n",
    "\n",
    "# Создаем модель\n",
    "!ollama create qwen-coder -f ./Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_print_output(process):\n",
    "    \"\"\"Helper function to continuously read and print process output\"\"\"\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Запуск SSH туннеля и Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка Ollama для удаленного доступа\n",
    "os.environ['OLLAMA_HOST'] = '0.0.0.0'\n",
    "os.environ['OLLAMA_ORIGINS'] = '*'\n",
    "\n",
    "# Создание SSH туннеля\n",
    "ssh_command = f\"ssh -N -R 0.0.0.0:{LOCAL_PORT}:localhost:{LOCAL_PORT} -o StrictHostKeyChecking=no -i {key_path} {VDS_USER}@{VDS_HOST}\"\n",
    "ssh_process = subprocess.Popen(\n",
    "    ssh_command.split(),\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "# Запуск Ollama\n",
    "print('>>> starting ollama serve')\n",
    "ollama_serve = subprocess.Popen(\n",
    "    ['ollama', 'serve'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    env=dict(os.environ)\n",
    ")\n",
    "\n",
    "serve_thread = threading.Thread(target=run_and_print_output, args=(ollama_serve,))\n",
    "serve_thread.daemon = True\n",
    "serve_thread.start()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> starting ollama pull qwen2.5-coder:14b')\n",
    "pull_process = subprocess.Popen(\n",
    "    ['ollama', 'pull', 'qwen2.5-coder:14b'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "while True:\n",
    "    output = pull_process.stdout.readline()\n",
    "    if output == '' and pull_process.poll() is not None:\n",
    "        break\n",
    "    if output:\n",
    "        print(output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Показать URL и поддерживать работу сервера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Your Ollama server is available at ===\")\n",
    "print(f\"http://{VDS_HOST}\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Shutting down...\")\n",
    "    ollama_serve.terminate()\n",
    "    ssh_process.terminate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
